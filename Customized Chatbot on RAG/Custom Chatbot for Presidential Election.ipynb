{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "124e5672",
      "cell_type": "markdown",
      "source": "# Custom Chatbot Project",
      "metadata": {}
    },
    {
      "id": "2a4a94b3",
      "cell_type": "markdown",
      "source": "I choose dataset wikipedia \"2024 United States presidential election\", because the gpt model doesn't have information about things happening in 2024. By providing these information, it can help ppl better understand what had happened during 2024 presidential election.",
      "metadata": {}
    },
    {
      "id": "a63d4c5f",
      "cell_type": "markdown",
      "source": "## Data Wrangling\n\nTODO: In the cells below, load your chosen dataset into a `pandas` dataframe with a column named `\"text\"`. This column should contain all of your text data, separated into at least 20 rows.",
      "metadata": {}
    },
    {
      "id": "c69b83a1",
      "cell_type": "code",
      "source": "import requests\n\n# Get the Wikipedia page for \"2024\" since OpenAI's models stop in 2021\nparams = {\n    \"action\": \"query\", \n    \"prop\": \"extracts\",\n    \"exlimit\": 1,\n    \"titles\": \"2024 United States presidential election\",\n    \"explaintext\": 1,\n    \"formatversion\": 2,\n    \"format\": \"json\"\n}\nresp = requests.get(\"https://en.wikipedia.org/w/api.php\", params=params)\n",
      "metadata": {},
      "outputs": [],
      "execution_count": 1
    },
    {
      "id": "0a595980",
      "cell_type": "code",
      "source": "import pandas as pd\n\n# Load page text into a dataframe\ncontent = resp.json()[\"query\"][\"pages\"][0][\"extract\"]\ndf = pd.DataFrame()\ndf[\"text\"] = content.split(\"\\n\")\ndf = df[(df[\"text\"].str.len() > 0) & (~df[\"text\"].str.startswith(\"==\"))]\nprint(df[\"text\"])",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "0      Presidential elections were held in the United...\n,1      The incumbent president, Joe Biden of the Demo...\n,2      Trump, who lost in 2020 to Biden, ran for re-e...\n,3      Trump achieved victory in the Electoral Colleg...\n,4      According to polls, the most important issues ...\n,                             ...                        \n,528    An Extremely Detailed Map of the 2024 Election...\n,529    \"Misinformation Dashboard: Election 2024. A to...\n,530    Dovere, Edward-Isaac (November 6, 2024). \"Wher...\n,531    \"The Choice 2024: Harris vs. Trump\". Frontline...\n,532    \"The VP Choice: Vance vs. Walz\". Frontline. Se...\n,Name: text, Length: 224, dtype: object\n"
        }
      ],
      "execution_count": 19
    },
    {
      "id": "ae769871",
      "cell_type": "markdown",
      "source": "## Custom Query Completion\n\nTODO: In the cells below, compose a custom query using your chosen dataset and retrieve results from an OpenAI `Completion` model. You may copy and paste any useful code from the course materials.",
      "metadata": {}
    },
    {
      "id": "582f0656",
      "cell_type": "code",
      "source": "import openai\nopenai.api_base = \"https://openai.vocareum.com/v1\"\nopenai.api_key = \"API_KEY\"",
      "metadata": {},
      "outputs": [],
      "execution_count": 21
    },
    {
      "id": "8b6e1f75",
      "cell_type": "code",
      "source": "# Verify GPT 3.5 is unware of 2024 US presidential election.\n\npresidential_prompt = \"\"\"\nQuestion: \"Who win the election of 2024 US presidential election\"\nAnswer:\n\"\"\"\ninitial_presidential_answer = openai.Completion.create(\n    model=\"gpt-3.5-turbo-instruct\",\n    prompt=presidential_prompt,\n    max_tokens=150\n)[\"choices\"][0][\"text\"].strip()\nprint(initial_presidential_answer)",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Unfortunately, it is impossible to accurately predict the outcome of the 2024 US presidential election at this time. The election will be determined by the American people through the voting process.\n"
        }
      ],
      "execution_count": 22
    },
    {
      "id": "13f2dcd7",
      "cell_type": "code",
      "source": "EMBEDDING_MODEL_NAME = \"text-embedding-ada-002\"\nbatch_size = 100\nembeddings = []\nfor i in range(0, len(df), batch_size):\n    # Send text data to OpenAI model to get embeddings\n    response = openai.Embedding.create(\n        input=df.iloc[i:i+batch_size][\"text\"].tolist(),\n        engine=EMBEDDING_MODEL_NAME\n    )\n    \n    # Add embeddings to list\n    embeddings.extend([data[\"embedding\"] for data in response[\"data\"]])\n\n# Add embeddings list to dataframe\ndf[\"embeddings\"] = embeddings",
      "metadata": {},
      "outputs": [],
      "execution_count": 23
    },
    {
      "id": "c403f543",
      "cell_type": "code",
      "source": "df.to_csv(\"embeddings.csv\")",
      "metadata": {},
      "outputs": [],
      "execution_count": 24
    },
    {
      "id": "74280b92",
      "cell_type": "code",
      "source": "from openai.embeddings_utils import get_embedding, distances_from_embeddings\n\ndef get_rows_sorted_by_relevance(question, df):\n    \"\"\"\n    Function that takes in a question string and a dataframe containing\n    rows of text and associated embeddings, and returns that dataframe\n    sorted from least to most relevant for that question\n    \"\"\"\n    \n    # Get embeddings for the question text\n    question_embeddings = get_embedding(question, engine=EMBEDDING_MODEL_NAME)\n    \n    # Make a copy of the dataframe and add a \"distances\" column containing\n    # the cosine distances between each row's embeddings and the\n    # embeddings of the question\n    df_copy = df.copy()\n    df_copy[\"distances\"] = distances_from_embeddings(\n        question_embeddings,\n        df_copy[\"embeddings\"].values,\n        distance_metric=\"cosine\"\n    )\n    \n    # Sort the copied dataframe by the distances and return it\n    # (shorter distance = more relevant so we sort in ascending order)\n    df_copy.sort_values(\"distances\", ascending=True, inplace=True)\n    return df_copy",
      "metadata": {},
      "outputs": [],
      "execution_count": 27
    },
    {
      "id": "88e4e98c",
      "cell_type": "code",
      "source": "get_rows_sorted_by_relevance(presidential_prompt, df)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>embeddings</th>\n",
              "      <th>distances</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>513</th>\n",
              "      <td>2024 United States elections</td>\n",
              "      <td>[-0.013307408429682255, -0.02391788363456726, ...</td>\n",
              "      <td>0.123527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>517</th>\n",
              "      <td>Timeline of the 2024 United States presidentia...</td>\n",
              "      <td>[-0.025916269049048424, -0.024590199813246727,...</td>\n",
              "      <td>0.126945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>514</th>\n",
              "      <td>2024 United States gubernatorial elections</td>\n",
              "      <td>[-0.014362308196723461, -0.013297007419168949,...</td>\n",
              "      <td>0.145521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>516</th>\n",
              "      <td>2024 United States Senate elections</td>\n",
              "      <td>[-0.01573183573782444, -0.024501660838723183, ...</td>\n",
              "      <td>0.149709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Presidential elections were held in the United...</td>\n",
              "      <td>[-0.04213929921388626, -0.032862551510334015, ...</td>\n",
              "      <td>0.153677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>359</th>\n",
              "      <td>Clayton County, Georgia â€“ 84.31%</td>\n",
              "      <td>[0.01413523405790329, 0.02612915262579918, -0....</td>\n",
              "      <td>0.308170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>271</th>\n",
              "      <td>\"tilt\" (used by some predictors): advantage th...</td>\n",
              "      <td>[-0.0323086641728878, -0.014604916796088219, 0...</td>\n",
              "      <td>0.309112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>365</th>\n",
              "      <td>Borden County, Texas â€“ 95.61%</td>\n",
              "      <td>[0.01437399722635746, 0.01590009219944477, -0....</td>\n",
              "      <td>0.313476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>364</th>\n",
              "      <td>Roberts County, Texas â€“ 95.63%</td>\n",
              "      <td>[0.006969737354665995, 0.019120965152978897, -...</td>\n",
              "      <td>0.314162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>360</th>\n",
              "      <td>Kalawao County, Hawaii â€“ 83.33%</td>\n",
              "      <td>[0.024022843688726425, 0.04104118421673775, 0....</td>\n",
              "      <td>0.316938</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>224 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text  \\\n",
              "513                       2024 United States elections   \n",
              "517  Timeline of the 2024 United States presidentia...   \n",
              "514         2024 United States gubernatorial elections   \n",
              "516                2024 United States Senate elections   \n",
              "0    Presidential elections were held in the United...   \n",
              "..                                                 ...   \n",
              "359                   Clayton County, Georgia â€“ 84.31%   \n",
              "271  \"tilt\" (used by some predictors): advantage th...   \n",
              "365                      Borden County, Texas â€“ 95.61%   \n",
              "364                     Roberts County, Texas â€“ 95.63%   \n",
              "360                    Kalawao County, Hawaii â€“ 83.33%   \n",
              "\n",
              "                                            embeddings  distances  \n",
              "513  [-0.013307408429682255, -0.02391788363456726, ...   0.123527  \n",
              "517  [-0.025916269049048424, -0.024590199813246727,...   0.126945  \n",
              "514  [-0.014362308196723461, -0.013297007419168949,...   0.145521  \n",
              "516  [-0.01573183573782444, -0.024501660838723183, ...   0.149709  \n",
              "0    [-0.04213929921388626, -0.032862551510334015, ...   0.153677  \n",
              "..                                                 ...        ...  \n",
              "359  [0.01413523405790329, 0.02612915262579918, -0....   0.308170  \n",
              "271  [-0.0323086641728878, -0.014604916796088219, 0...   0.309112  \n",
              "365  [0.01437399722635746, 0.01590009219944477, -0....   0.313476  \n",
              "364  [0.006969737354665995, 0.019120965152978897, -...   0.314162  \n",
              "360  [0.024022843688726425, 0.04104118421673775, 0....   0.316938  \n",
              "\n",
              "[224 rows x 3 columns]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 28
    },
    {
      "id": "30df6575",
      "cell_type": "code",
      "source": "import tiktoken\n\ndef create_prompt(question, df, max_token_count):\n    \"\"\"\n    Given a question and a dataframe containing rows of text and their\n    embeddings, return a text prompt to send to a Completion model\n    \"\"\"\n    # Create a tokenizer that is designed to align with our embeddings\n    tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n    \n    # Count the number of tokens in the prompt template and question\n    prompt_template = \"\"\"\nAnswer the question based on the context below, and if the question\ncan't be answered based on the context, say \"I don't know\"\n\nContext: \n\n{}\n\n---\n\nQuestion: {}\nAnswer:\"\"\"\n    \n    current_token_count = len(tokenizer.encode(prompt_template)) + \\\n                            len(tokenizer.encode(question))\n    \n    context = []\n    for text in get_rows_sorted_by_relevance(question, df)[\"text\"].values:\n        \n        # Increase the counter based on the number of tokens in this row\n        text_token_count = len(tokenizer.encode(text))\n        current_token_count += text_token_count\n        \n        # Add the row of text to the list if we haven't exceeded the max\n        if current_token_count <= max_token_count:\n            context.append(text)\n        else:\n            break\n\n    return prompt_template.format(\"\\n\\n###\\n\\n\".join(context), question)",
      "metadata": {},
      "outputs": [],
      "execution_count": 29
    },
    {
      "id": "c19b1c79",
      "cell_type": "code",
      "source": "COMPLETION_MODEL_NAME = \"gpt-3.5-turbo-instruct\"\n\ndef answer_question(\n    question, df, max_prompt_tokens=1800, max_answer_tokens=150\n):\n    \"\"\"\n    Given a question, a dataframe containing rows of text, and a maximum\n    number of desired tokens in the prompt and response, return the\n    answer to the question according to an OpenAI Completion model\n    \n    If the model produces an error, return an empty string\n    \"\"\"\n    \n    prompt = create_prompt(question, df, max_prompt_tokens)\n    \n    try:\n        response = openai.Completion.create(\n            model=COMPLETION_MODEL_NAME,\n            prompt=prompt,\n            max_tokens=max_answer_tokens\n        )\n        return response[\"choices\"][0][\"text\"].strip()\n    except Exception as e:\n        print(e)\n        return \"\"\n        ",
      "metadata": {},
      "outputs": [],
      "execution_count": 30
    },
    {
      "id": "2e543c32",
      "cell_type": "code",
      "source": "custom_presidential_answer = answer_question(presidential_prompt, df)\nprint(custom_presidential_answer)",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Donald Trump won the 2024 US presidential election.\n"
        }
      ],
      "execution_count": 31
    },
    {
      "id": "1783f146",
      "cell_type": "markdown",
      "source": "## Custom Performance Demonstration\n\nTODO: In the cells below, demonstrate the performance of your custom query using at least 2 questions. For each question, show the answer from a basic `Completion` model query as well as the answer from your custom query.",
      "metadata": {}
    },
    {
      "id": "4f11fdc0",
      "cell_type": "markdown",
      "source": "### Question 1",
      "metadata": {}
    },
    {
      "id": "4901c850",
      "cell_type": "code",
      "source": "presidential_prompt_1 = \"\"\"\nQuestion: \"Does anyone interfere 2024 US presidential election\"\nAnswer:\n\"\"\"",
      "metadata": {},
      "outputs": [],
      "execution_count": 32
    },
    {
      "id": "bd7a093b",
      "cell_type": "code",
      "source": "initial_presidential_answer_1 = openai.Completion.create(\n    model=\"gpt-3.5-turbo-instruct\",\n    prompt=presidential_prompt_1,\n    max_tokens=150\n)[\"choices\"][0][\"text\"].strip()\nprint(initial_presidential_answer)",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Unfortunately, it is impossible to accurately predict the outcome of the 2024 US presidential election at this time. The election will be determined by the American people through the voting process.\n"
        }
      ],
      "execution_count": 33
    },
    {
      "id": "015fc4c9",
      "cell_type": "code",
      "source": "custom_presidential_answer_1 = answer_question(\"Does anyone interfere 2024 US presidential election\", df)\nprint(custom_presidential_answer_1)",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Yes, multiple countries such as China, Russia, and Iran were identified as attempting to interfere with the 2024 US Presidential Election through various means including propaganda, disinformation campaigns, and hacking attempts.\n"
        }
      ],
      "execution_count": 34
    },
    {
      "id": "6e86e37c",
      "cell_type": "markdown",
      "source": "### Question 2",
      "metadata": {}
    },
    {
      "id": "6f646989",
      "cell_type": "code",
      "source": "presidential_prompt_2 = \"\"\"\nQuestion: \"Did Nikki Haley beat Donald Trump in the election?\"\nAnswer:\n\"\"\"",
      "metadata": {},
      "outputs": [],
      "execution_count": 36
    },
    {
      "id": "11c07a54",
      "cell_type": "code",
      "source": "initial_presidential_answer_2 = openai.Completion.create(\n    model=\"gpt-3.5-turbo-instruct\",\n    prompt=presidential_prompt_2,\n    max_tokens=150\n)[\"choices\"][0][\"text\"].strip()\nprint(initial_presidential_answer)",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Unfortunately, it is impossible to accurately predict the outcome of the 2024 US presidential election at this time. The election will be determined by the American people through the voting process.\n"
        }
      ],
      "execution_count": 37
    },
    {
      "id": "4d5e30e6",
      "cell_type": "code",
      "source": "custom_presidential_answer_2 = answer_question(\"Did Nikki Haley beat Donald Trump in the election?\", df)\nprint(custom_presidential_answer_2)",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "No\n"
        }
      ],
      "execution_count": 38
    },
    {
      "id": "920f3be7",
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    }
  ]
}